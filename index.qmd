---
title: "Land Cover to Satellite Image Translation with Pix2Pix"
subtitle: "Applying Generative Adversarial Networks for Image-to-Map Conversion"
---

## Welcome!

This research explores the application of a Pix2Pix Generative Adversarial Network (GAN) model to translate from land cover maps to satellite imagery. By the use of 1,000 paired datasets sourced from diverse land cover types, the project aims to train a conditional GAN capable of producing realistic satellite images from land cover data.

The study is meaningful as it provides a method for visualizing landscape changes and potential future developments. Such a tool can simulate and assess the impact of urbanization, land-use planning, or ecological shifts by generating predictive satellite imagery based on hypothetical scenarios. The integration of machine learning and geospatial data provides a useful tool in environmental planning, offering a scalable solution for decision-makers.

